# 架构级分析报告：面向稀疏/稠密统一求解器的软硬协同设计

> 依据你在《问题总结1107.md》中提出的想法与问题，面向“硬件侧含简易 CPU（RV64）+ 简易 TPU”的加速平台，给出一份工程化、可落地的评审与建议。

------

## 引言

你提出两项关键设想：（a）**缓存并复用消解树/调度**以缩短冷启动；（b）在**RV64 简易 CPU 上以“指令/工作队列”形式做调度**，并按任务类型选择由 CPU 或 TPU 执行。同时，你希望系统性解答混合精度与迭代改进、front 很小时的处理策略、前沿组装的访存不规则问题、固件调度角色，以及 **2D block-cyclic** 的工程含义与用法。

下文从架构师视角，按“**可复用性/调度**—**数值路径与混合精度**—**小 front 性能**—**front 组装访存**—**固件调度定位**—**2D block-cyclic**”展开，最后给出可执行的建议清单与结论。你的输出格式要求（引言、分析、建议、结论）已在结构中体现。

------

## 分析

### A. 消解树/符号分析的复用与“硬件侧缓存”是否必要？

**事实依据与可行性**
对于**相同稀疏结构**（图结构不变）的多次求解，主流做法是**重用排序与符号分解**，跳过昂贵的分析阶段，只做数值分解和求解。高性能计算培训资料与求解器文档均建议：当稀疏模式不变时，**复用排序与符号因子**可显著降耗。[极限计算培训](https://extremecomputingtraining.anl.gov/wp-content/uploads/sites/96/2025/08/DirectSolvers_ATPESC-2025.pdf?utm_source=chatgpt.com) 同时，多体裁资料（书/讲义）也说明：符号分解本质是**预测填充与前沿结构**，模式不变则符号信息可复用。[eClass+2工程人员网站+2](https://eclass.uth.gr/modules/document/file.php/E-CE_U_104/Timothy A. Davis Direct methods for sparse linear systems.pdf?utm_source=chatgpt.com)

**是否要把“复用信息”放在硬件侧长期缓存？**

- **收益**：对“同构”输入（同一应用、同一网格/电路拓扑）反复求解时，硬件侧直接命中“前沿脚本（front DAG + 调度参数）”，可缩短主机到设备的启动控制路径，提升吞吐。
- **代价**：需要**跨主机/设备保持缓存一致性**（版本、哈希、失效策略），并承担“轻微结构变更导致缓存失配”的复杂度（重排稍变即失效）。
- **折中建议**：
  1. **缓存主从分离**：把“**全量符号/调度知识库**”放在**软件侧**（主机/驱动层），硬件仅缓存“**本次会话的前沿脚本**”（如 N 条命令 + 若干参数表）；
  2. 使用**轻量指纹**（例如对 CSR/CSC 结构的哈希 + 排序版本号 + 规模阈值）在**会话开始时一次性校验**，未命中则由主机重下发脚本；
  3. 硬件侧可保留**小容量 LRU**（“计分牌”）以加速**同一会话内**的重复分块/子图；跨会话的大缓存交给软件维护，避免设备端一致性成本。
     整体看，这是**“有益但非必要”**的优化；若你的实际工作负载 \**确实高概率重复\**（如时步仿真、参数扫描），才建议做**薄缓存**版本以降低风险。

------

### B. RV64 简易 CPU 的“指令/工作队列”与 CPU/TPU 协同

将整体算法拆成**可复用的运行原语**（opcodes），由主机批量下发到设备侧**工作队列**，由 RV64 进行**微调度/资源编排**，是工程上稳妥的做法。建议的最小**命令集（草案）**：

- **DMA/Gather-Scatter**：`DMA_IN(desc[])` / `DMA_OUT(desc[])`（支持不连续段，变量长）；AMD/赛灵思的 AXI DMA **散/聚**模式是标准做法，可用**描述符链**表达不定长与多片段搬运。[AMD 文档+2AMD 文档+2](https://docs.amd.com/r/en-US/pg021_axi_dma?utm_source=chatgpt.com)
- **分解原语**：`PANEL_GEPP(nb, tol, pivot_mode)`；`TRSM(side,uplo,trans,batch)`；`GEMM_UPDATE(tile_desc)`；
- **求解原语**：`SOLVE_FW` / `SOLVE_BW`；
- **数值策略**：`SET_PREC(mixed_mode)`（bf16/FP16 分解 + FP32/64 累加/残差）
- **控制/同步**：`BARRIER(tag)` / `FENCE_IO`；完成队列 `CQ` + **doorbell** 寄存器做提交/完成通知。

**策略**：

- **策略在主机，机制在 RV64**。主机保留“**DAG/前沿队列**”的全局策略；RV64 负责双缓冲、通道分配和队列推进，TPU 专注于 **TRSM/GEMM/AXPY** 等算子吞吐。
- **失败回退路径**：在 RV64 层面保留对 pivot 阈值/候选失败的**快速回退**（提高阈值、切换模式、重新装入面板）。

------

### C. 混合精度与迭代改进（IR）：为什么、如何做、何时有效

**为什么需要**

- 现代加速器在 **低精度**（bf16/FP16）上吞吐更高、能效更好；
- **先低精度分解，后用高精度残差校正**（IR）可以把解的精度恢复到 **FP64 级**，这是 HPL-MxP/HPL-AI 的核心路线。[arXiv+2SAGE Journals+2](https://arxiv.org/abs/2509.19618?utm_source=chatgpt.com)

**软件侧怎么实现（算法骨架）**

1. **低精度**完成 `LU ≈ PA`（可 FP32 累加）；
2. 解 `Ly = Pb`、`Ux = y` 得到初解 `x₀`；
3. **高精度**计算残差 `r = b − Ax₀`；
4. 解校正方程 `A δx = r`（可继续走低精度因子 + 高精度残差）；
5. `x ← x + δx`，若 `||r||` 未达标，继续迭代或切换到 **GMRES-IR**（非定常 IR，收敛性更强）。该框架已被系统化研究与验证。[SIAM Ebooks](https://epubs.siam.org/doi/10.1137/17M1140819?utm_source=chatgpt.com)

**何时有效/失效**

- **适用**：中等条件数的问题（或经良好缩放/匹配后）；
- **可能失效**：强不定/病态系统；此时采用 **GMRES-IR**、更强的预处理或回退到全精度。[SIAM Ebooks+1](https://epubs.siam.org/doi/10.1137/17M1140819?utm_source=chatgpt.com)

------

### D. front 很小（128/256）时如何处理？

**问题本质**：阻塞 LU 的优势在于 **面板宽度 NB 足够大** 时 TRSM/GEMM 的效率；当 front 很小，启动/搬运开销主导。

**工程对策**

- **阈值切换**：小于阈值（例如 `< 128`）时使用**非阻塞算法（DGETF2 风格）\**或\**微内核路径**；
- **批式（batched）执行**：把**多个小 front** 合并为**批任务**一次提交，显著提升阵列/流水利用率；MAGMA 对**小矩阵批式**有大量实证与内核设计经验可借鉴。[icl.utk.edu+2icl.utk.edu+2](https://icl.utk.edu/files/publications/2016/icl-utk-909-2016.pdf?utm_source=chatgpt.com)
- **前沿拼接**：对极小 front，允许在 SRAM 中**拼接成 mini-panel** 后再进入 TRSM/GEMM。

------

### E. 前沿（front）组装的多次/不定长访存怎么做？

**背景**：多重前沿法的**extend-add**会把子前沿的贡献汇入父前沿，天然涉及**稀疏到稠密**的“散/聚”访问与累加。权威教材与调研综述对其代价与实现细节有系统说明。[eClass+1](https://eclass.uth.gr/modules/document/file.php/E-CE_U_104/Timothy A. Davis Direct methods for sparse linear systems.pdf?utm_source=chatgpt.com)

**工程做法（两段式）**

1. **软件端**（主机）根据符号信息，预先生成**front 组装清单**：每个 front 的**贡献块列表**（起始偏移、行列范围、大小）。
2. **设备端**（RV64 + DMA）：
   - 用 **AXI DMA 散/聚（Scatter/Gather）\**把多个不连续片段搬入\**片上 SRAM 的“组装区”**；
   - 在 SRAM 内执行**规整化累加**（避免在 DDR 上做细粒度随机写）；
   - 完成后一次性回写（**写回融合**）。AXI DMA 的 SG 模式天然支持**多描述符链**与**可变长度**，非常适合该场景。[AMD 文档+2AMD 文档+2](https://docs.amd.com/r/en-US/pg021_axi_dma?utm_source=chatgpt.com)

------

### F. 固件（Firmware）调度应扮演什么角色？

把固件理解成“**可自启动的微运行时**”更贴切，而非 PC 语境的 BIOS。对矩阵求解而言，**让固件做全局 DAG 调度并非必须**，更推荐：

- **主机掌控全局 DAG/策略**：包含 front 的拓扑顺序、资源目标与精度策略；
- **固件负责“机制”**：双缓冲、DMA 队列、候选主元筛选与**局部重试**、完成队列等“常数因子优化”；
- **自动化程度**控制在“**能独立推进一批队列**”即可（如批 front 组装/分解/写回三段式），而不承诺“**跨批次的全局最优**”。
  这种分工能降低复杂度，同时更容易和主机侧的算法演进（重排、混合精度策略）保持同步。

------

### G. 什么是 **2D block-cyclic**？为何建议在你的系统里用？

**概念与性质**
ScaLAPACK 的**二维块循环分布**把矩阵切成 `NB×NB` 的块，按**进程网格**（或你的场景下的**多通道/多 bank 资源网格**）**循环轮转**地分配，能在理论与实践上**均衡负载**、**摊平热点**并提升并行度。权威手册对该布局、局部存储和映射有清晰说明。[netlib.org+2netlib.org+2](https://www.netlib.org/scalapack/slug/node75.html?utm_source=chatgpt.com)

**映射到你的硬件**

- 把“进程网格”类比为**(DDR 通道 × bank 组)** 的资源网格；
- 选择与你的面板/更新核匹配的 `NB`（常见在 **128/256** 一档；与 SRAM 容量、burst 长度、TPU tile 尺寸对齐）；
- **front 更新写回**也遵循该布局，配合**写回融合**减少跨通道反复搬运。
  这会在工程上**显著降低某个通道/Bank 的热点**，提高带宽利用率与“尾部”效率。

------

## 建议（可直接落地）

1. **复用/缓存策略**
   - 把**全量符号与调度知识**放在主机；硬件侧仅缓存**当前会话脚本**（LRU ≤十几条）。
   - 定义**Pattern-ID**（CSR/CSC 哈希 + 排序版本号 + 规模阈值），会话开始一次校验；不命中则重新下发。[极限计算培训](https://extremecomputingtraining.anl.gov/wp-content/uploads/sites/96/2025/08/DirectSolvers_ATPESC-2025.pdf?utm_source=chatgpt.com)
2. **RV64 工作队列与命令集**
   - 实现 **doorbell + submission queue + completion queue**；
   - 支持 **AXI-DMA SG** 描述符链，front 组装/写回均走**散/聚 + 写回融合**。[AMD 文档](https://docs.amd.com/r/en-US/pg021_axi_dma?utm_source=chatgpt.com)
3. **数值路径**
   - 默认 **LU +（可选）GMRES-IR** 路线：分解用 bf16/FP16（FP32 累加），残差/校正用 FP32/64；失败时自动回退到全精度。[SIAM Ebooks+1](https://epubs.siam.org/doi/10.1137/17M1140819?utm_source=chatgpt.com)
   - 对“显式逆/高稳健性”强需求再引入 **CAQR/TSQR** 路径，重用相同 DMA/SRAM/调度骨架。
4. **小 front 性能**
   - `<128` 走**非阻塞/微内核**；`128–256` 走阻塞；
   - 多个小 front 采用**batch 提交**，在 TPU 上共享一次 kernel 启动与管线填充。[icl.utk.edu+1](https://icl.utk.edu/files/publications/2016/icl-utk-909-2016.pdf?utm_source=chatgpt.com)
5. **front 组装**
   - 主机输出**贡献清单**（offset, shape, stride）；设备以 **SG-DMA** 汇入 SRAM“组装区”，**局部累加**后一次**融合写回**；
   - 通过**环形缓冲 + 描述符池**支撑“变长、多段”的稳定吞吐。[eClass+1](https://eclass.uth.gr/modules/document/file.php/E-CE_U_104/Timothy A. Davis Direct methods for sparse linear systems.pdf?utm_source=chatgpt.com)
6. **固件调度定位**
   - 固件做**机制层自动化**（双缓冲、重试、通道分配），主机保留**策略与全局顺序**；
   - 固件提供“**自治推进一批 front**”的模式，便于在主机阻塞或延迟时保持设备利用率。
7. **2D block-cyclic 内存映射**
   - 以 `NB=128/256` 起步，和 SRAM/TPU tile 对齐；
   - 在 **(通道×bank)** 网格上循环分配，辅助**负载均衡**与**热点摊平**；
   - 更新/写回阶段同样遵循该布局，减少搬运回流。[netlib.org+1](https://www.netlib.org/scalapack/slug/node75.html?utm_source=chatgpt.com)
8. **通信规避与主元策略**
   - 面板分解采用 **CALU/tournament** 思想降低同步与消息数；与“地址级延迟交换（ATU）”协同，减少真实行交换。[netlib.org+2icl.utk.edu+2](https://www.netlib.org/lapack/lawnspdf/lawn226.pdf?utm_source=chatgpt.com)

------

## 结论

- **复用分析/符号阶段**是正确方向，但**硬件端长期缓存**应谨慎：先做**薄会话缓存**，把一致性与版本控制放在主机侧。
- **RV64 + 工作队列 + SG-DMA**是稳妥的**机制层**：主机决策、固件推进、TPU 吞吐。
- **混合精度 + IR**能以低精度吞吐换来高精度解，工程上应做成**默认路径 + 失败回退**。
- **小 front**必须靠**阈值切换 + batched**维持效率；
- **front 组装**用**两段式 + SG-DMA + 写回融合**抑制不规则访存；
- **2D block-cyclic**应下沉为**默认内存映射策略**，在你的平台里对应“通道×bank 网格”的负载均衡器；
- 结合 **CALU** 与 **ATU**，可以显著缓解“串行 pivot + 真实行交换”的瓶颈。

> 以上分析与建议与您文档中的目标和问题一一对应，供你把控设计边界并安排下一步实现与评测。

------

### 参考资料（精选）

- **复用符号分析/排序（相同稀疏模式）**：Argonne 直解/预处理培训材料，明确提出“**同模式系统复用排序与符号因子**”。[极限计算培训](https://extremecomputingtraining.anl.gov/wp-content/uploads/sites/96/2025/08/DirectSolvers_ATPESC-2025.pdf?utm_source=chatgpt.com)
- **多前沿/extend-add 与教材**：Davis《Direct Methods for Sparse Linear Systems》、Davis 综述。[eClass+1](https://eclass.uth.gr/modules/document/file.php/E-CE_U_104/Timothy A. Davis Direct methods for sparse linear systems.pdf?utm_source=chatgpt.com)
- **CALU（通信规避 LU，tournament pivoting）**：LAWN#226 与后续实现文献。[netlib.org+2icl.utk.edu+2](https://www.netlib.org/lapack/lawnspdf/lawn226.pdf?utm_source=chatgpt.com)
- **混合精度与迭代改进**：Carson & Higham（SIAM 2018，三精度 IR），HPL-MxP/HPL-AI 基准与论文。[hpl-mxp.org+3SIAM Ebooks+3arXiv+3](https://epubs.siam.org/doi/10.1137/17M1140819?utm_source=chatgpt.com)
- **小矩阵批式（batched）核**：MAGMA 系列文献与报告。[icl.utk.edu+2netlib.org+2](https://icl.utk.edu/files/publications/2016/icl-utk-909-2016.pdf?utm_source=chatgpt.com)
- **2D block-cyclic（ScaLAPACK 手册）**：分布、局部存储与映射细节。[netlib.org+2netlib.org+2](https://www.netlib.org/scalapack/slug/node75.html?utm_source=chatgpt.com)
- **AXI DMA 散/聚（SG）模式**：PG021 产品手册与在线文档。[AMD 文档+1](https://docs.amd.com/r/en-US/pg021_axi_dma?utm_source=chatgpt.com)

